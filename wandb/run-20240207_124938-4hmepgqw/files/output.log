Train batch 0: Loss --- 0.7036404013633728
Train batch 1: Loss --- 0.663124144077301
Train batch 2: Loss --- 0.6702448725700378
Train batch 3: Loss --- 0.6492537260055542
Train batch 4: Loss --- 0.6337583065032959
Train batch 5: Loss --- 0.6504025459289551
Train batch 6: Loss --- 0.5920464396476746
Train batch 7: Loss --- 0.636789083480835
Train batch 8: Loss --- 0.6283412575721741
Train batch 9: Loss --- 0.5792815089225769
Train batch 10: Loss --- 0.5488365888595581
Train batch 11: Loss --- 0.5676670074462891
Train batch 12: Loss --- 0.5683000087738037
Train batch 13: Loss --- 0.594340443611145
Train batch 14: Loss --- 0.5606485605239868
Train batch 15: Loss --- 0.5036814212799072
Train batch 16: Loss --- 0.5374069809913635
Train batch 17: Loss --- 0.5336781144142151
Train batch 18: Loss --- 0.5026728510856628
Train batch 19: Loss --- 0.5377210378646851
Train batch 20: Loss --- 0.488918662071228
Train batch 21: Loss --- 0.5950853824615479
Train batch 22: Loss --- 0.4694737493991852
Train batch 23: Loss --- 0.4111582934856415
Train batch 24: Loss --- 0.5287877321243286
Train batch 25: Loss --- 0.45778676867485046
Train batch 26: Loss --- 0.39365971088409424
Train batch 27: Loss --- 0.4504380226135254
Train batch 28: Loss --- 0.41377004981040955
Train batch 29: Loss --- 0.47422167658805847
Train batch 30: Loss --- 0.3882870376110077
Train batch 31: Loss --- 0.6036382913589478
Train batch 32: Loss --- 0.5700726509094238
Train batch 33: Loss --- 0.5342922210693359
Train batch 34: Loss --- 0.4613837003707886
Train batch 35: Loss --- 0.4026191532611847
Train batch 36: Loss --- 0.3676496744155884
Train batch 37: Loss --- 0.4952738583087921
Train batch 38: Loss --- 0.3674582242965698
Train batch 39: Loss --- 0.3203345239162445
Train batch 40: Loss --- 0.5513893961906433
Train batch 41: Loss --- 0.3458692729473114
Train batch 42: Loss --- 0.49399060010910034
Train batch 43: Loss --- 0.47993534803390503
Train batch 44: Loss --- 0.48068299889564514
Train batch 45: Loss --- 0.5721595287322998
Train batch 46: Loss --- 0.5250524282455444
Train batch 47: Loss --- 0.4583527147769928
Train batch 48: Loss --- 0.3765698969364166
Train batch 49: Loss --- 0.5413232445716858
Train batch 50: Loss --- 0.37269946932792664
Train batch 51: Loss --- 0.4948466122150421
Train batch 52: Loss --- 0.39774176478385925
Train batch 53: Loss --- 0.4783829152584076
Train batch 54: Loss --- 0.478718101978302
Train batch 55: Loss --- 0.407396137714386
Train batch 56: Loss --- 0.7082581520080566
Train batch 57: Loss --- 0.4284871518611908
Train batch 58: Loss --- 0.29983967542648315
Train batch 59: Loss --- 0.4326666295528412
Train batch 60: Loss --- 0.46678435802459717
Train batch 61: Loss --- 0.3550465703010559
Train batch 62: Loss --- 0.4578017592430115
Train batch 63: Loss --- 0.3558998107910156
Train batch 64: Loss --- 0.4891487956047058
Train batch 65: Loss --- 0.3539721965789795
Train batch 66: Loss --- 0.40871313214302063
Train batch 67: Loss --- 0.631645679473877
Train batch 68: Loss --- 0.3916368782520294
Train batch 69: Loss --- 0.35562190413475037
Train batch 70: Loss --- 0.3776664435863495
Train batch 71: Loss --- 0.4713316559791565
Train batch 72: Loss --- 0.5416139960289001
Train batch 73: Loss --- 0.48007330298423767
Train batch 74: Loss --- 0.4092516601085663
Train batch 75: Loss --- 0.37657368183135986
Train batch 76: Loss --- 0.4379711449146271
Train batch 77: Loss --- 0.4246019423007965
Train batch 78: Loss --- 0.36391764879226685
Train batch 79: Loss --- 0.4977164566516876
Train batch 80: Loss --- 0.519917368888855
Train batch 81: Loss --- 0.4082748591899872
Train batch 82: Loss --- 0.49270686507225037
Train batch 83: Loss --- 0.3914136290550232
Train batch 84: Loss --- 0.3556462228298187
Train batch 85: Loss --- 0.5259796380996704
Train batch 86: Loss --- 0.49067893624305725
Train batch 87: Loss --- 0.41431838274002075
Train batch 88: Loss --- 0.43958306312561035
Train batch 89: Loss --- 0.419739305973053
Train batch 90: Loss --- 0.4167027771472931
Train batch 91: Loss --- 0.32389992475509644
Train batch 92: Loss --- 0.4115189015865326
Train batch 93: Loss --- 0.45247599482536316
Train batch 94: Loss --- 0.5152051448822021
Train batch 95: Loss --- 0.33901166915893555
Train batch 96: Loss --- 0.3939175009727478
Train batch 97: Loss --- 0.4519902467727661
Train batch 98: Loss --- 0.3387281000614166
Train batch 99: Loss --- 0.596903920173645
Train batch 100: Loss --- 0.26559409499168396
Train batch 101: Loss --- 0.30627018213272095
Train batch 102: Loss --- 0.40715843439102173
Train batch 103: Loss --- 0.3552328646183014
Train batch 104: Loss --- 0.3186098337173462
Train batch 105: Loss --- 0.3840867280960083
Train batch 106: Loss --- 0.33180493116378784
Train batch 107: Loss --- 0.36018577218055725
Train batch 108: Loss --- 0.3160662055015564
Train batch 109: Loss --- 0.31569704413414
Train batch 110: Loss --- 0.3953864872455597
Train batch 111: Loss --- 0.3830459713935852
Train batch 112: Loss --- 0.29514986276626587
Train batch 113: Loss --- 0.4012369215488434
Train batch 114: Loss --- 0.4484788477420807
Train batch 115: Loss --- 0.27141621708869934
Train batch 116: Loss --- 0.4275544583797455
Train batch 117: Loss --- 0.4574374556541443
Train batch 118: Loss --- 0.32773464918136597
Train batch 119: Loss --- 0.4305020570755005
Train batch 120: Loss --- 0.41536006331443787
Train batch 121: Loss --- 0.40300866961479187
Train batch 122: Loss --- 0.38018447160720825
Train batch 123: Loss --- 0.3359479606151581
Train batch 124: Loss --- 0.22488747537136078
Train batch 125: Loss --- 0.4593763053417206
Train batch 126: Loss --- 0.3750718832015991
Train batch 127: Loss --- 0.46191078424453735
Train batch 128: Loss --- 0.40041583776474
Train batch 129: Loss --- 0.5008475184440613
Train batch 130: Loss --- 0.2376384437084198
Train batch 131: Loss --- 0.30548763275146484
Train batch 132: Loss --- 0.40599822998046875
Train batch 133: Loss --- 0.6078416109085083
Train batch 134: Loss --- 0.2972387373447418
Train batch 135: Loss --- 0.5095272660255432
Train batch 136: Loss --- 0.3418842554092407
Train batch 137: Loss --- 0.5559297204017639
Train batch 138: Loss --- 0.2548130452632904
Train batch 139: Loss --- 0.3000532388687134
Train batch 140: Loss --- 0.31065770983695984
Train batch 141: Loss --- 0.2647677958011627
Train batch 142: Loss --- 0.3530488610267639
Train batch 143: Loss --- 0.35268548130989075
Train batch 144: Loss --- 0.3310929238796234
Train batch 145: Loss --- 0.28437110781669617
Train batch 146: Loss --- 0.23292870819568634
Train batch 147: Loss --- 0.3595273494720459
Train batch 148: Loss --- 0.3883874714374542
Train batch 149: Loss --- 0.43475669622421265
Train batch 150: Loss --- 0.42643117904663086
Train batch 151: Loss --- 0.3863525390625
Train batch 152: Loss --- 0.5662376880645752
Train batch 153: Loss --- 0.6162741184234619
Train batch 154: Loss --- 0.19857670366764069
Train batch 155: Loss --- 0.29503053426742554
Train batch 156: Loss --- 0.23907549679279327
Train batch 157: Loss --- 0.36854299902915955
Train batch 158: Loss --- 0.3976875841617584
Train batch 159: Loss --- 0.4232962131500244
Train batch 160: Loss --- 0.2244822382926941
Train batch 161: Loss --- 0.2748787999153137
Train batch 162: Loss --- 0.42451539635658264
Train batch 163: Loss --- 0.3142416179180145
Train batch 164: Loss --- 0.47800710797309875
Train batch 165: Loss --- 0.39229825139045715
Train batch 166: Loss --- 0.25365233421325684
Train batch 167: Loss --- 0.4032142162322998
Train batch 168: Loss --- 0.4711764454841614
Train batch 169: Loss --- 0.3340836763381958
Train batch 170: Loss --- 0.2890458405017853
Train batch 171: Loss --- 0.37078821659088135
Train batch 172: Loss --- 0.369291216135025
Train batch 173: Loss --- 0.2335720807313919
Train batch 174: Loss --- 0.3840644955635071
Train batch 175: Loss --- 0.33160775899887085
Train batch 176: Loss --- 0.30910390615463257
Train batch 177: Loss --- 0.40163758397102356
Train batch 178: Loss --- 0.5137239098548889
Train batch 179: Loss --- 0.2967393398284912
Train batch 180: Loss --- 0.23476840555667877
Train batch 181: Loss --- 0.23741565644741058
Train batch 182: Loss --- 0.3880508840084076
Train batch 183: Loss --- 0.23797978460788727
Train batch 184: Loss --- 0.30331334471702576
Train batch 185: Loss --- 0.33224520087242126
Train batch 186: Loss --- 0.3702809512615204
Train batch 187: Loss --- 0.19094742834568024
Train batch 188: Loss --- 0.26852256059646606
Train batch 189: Loss --- 0.4061747193336487
Train batch 190: Loss --- 0.22592860460281372
Train batch 191: Loss --- 0.3023219406604767
Train batch 192: Loss --- 0.3263215124607086
Train batch 193: Loss --- 0.35370784997940063
Train batch 194: Loss --- 0.1657114177942276
Train batch 195: Loss --- 0.37139371037483215
Train batch 196: Loss --- 0.5619696378707886
Train batch 197: Loss --- 0.47095149755477905
Train batch 198: Loss --- 0.24109406769275665
Train batch 199: Loss --- 0.36240601539611816
Train batch 200: Loss --- 0.2964187264442444
Train batch 201: Loss --- 0.6093124151229858
Train batch 202: Loss --- 0.18362534046173096
Train batch 203: Loss --- 0.35622096061706543
Train batch 204: Loss --- 0.4018210172653198
Train batch 205: Loss --- 0.4432935416698456
Train batch 206: Loss --- 0.25645962357521057
Train batch 207: Loss --- 0.27011609077453613
Train batch 208: Loss --- 0.47328445315361023
Train batch 209: Loss --- 0.18467946350574493
Train batch 210: Loss --- 0.40498366951942444
Train batch 211: Loss --- 0.426832377910614
Train batch 212: Loss --- 0.3994198739528656
Train batch 213: Loss --- 0.19156554341316223
Train batch 214: Loss --- 0.2544142007827759
Train batch 215: Loss --- 0.22022530436515808
Train batch 216: Loss --- 0.30185163021087646
Train batch 217: Loss --- 0.2649773955345154
Train batch 218: Loss --- 0.40534892678260803
Train batch 219: Loss --- 0.39244723320007324
Train batch 220: Loss --- 0.3126732409000397
Train batch 221: Loss --- 0.44922974705696106
Train batch 222: Loss --- 0.529400646686554
Train batch 223: Loss --- 0.18398138880729675
Train batch 224: Loss --- 0.47560545802116394
Train batch 225: Loss --- 0.6235891580581665
Train batch 226: Loss --- 0.2832389175891876
Train batch 227: Loss --- 0.29353535175323486
Train batch 228: Loss --- 0.2999456524848938
Train batch 229: Loss --- 0.48130959272384644
Train batch 230: Loss --- 0.3387308716773987
Train batch 231: Loss --- 0.25392407178878784
Train batch 232: Loss --- 0.43700122833251953
Train batch 233: Loss --- 0.3209858536720276
Train batch 234: Loss --- 0.20083291828632355
Train batch 235: Loss --- 0.4098874628543854
Train batch 236: Loss --- 0.2880832552909851
Train batch 237: Loss --- 0.3412845730781555
Train batch 238: Loss --- 0.28535333275794983
Train batch 239: Loss --- 0.3071692883968353
Train batch 240: Loss --- 0.2003439962863922
Train batch 241: Loss --- 0.414567768573761
Train batch 242: Loss --- 0.31804609298706055
Train batch 243: Loss --- 0.24378232657909393
Train batch 244: Loss --- 0.32731232047080994
Train batch 245: Loss --- 0.23766176402568817
Train batch 246: Loss --- 0.3383328914642334
Train batch 247: Loss --- 0.585834801197052
Train batch 248: Loss --- 0.36063534021377563
Train batch 249: Loss --- 0.33099669218063354
Train batch 250: Loss --- 0.1850513219833374
Train batch 251: Loss --- 0.3497049808502197
Train batch 252: Loss --- 0.23131875693798065
Train batch 253: Loss --- 0.2928321063518524
Train batch 254: Loss --- 0.30673274397850037
Train batch 255: Loss --- 0.3344917595386505
Train batch 256: Loss --- 0.41992658376693726
Train batch 257: Loss --- 0.2779805660247803
Train batch 258: Loss --- 0.43569985032081604
Train batch 259: Loss --- 0.3269723653793335
Train batch 260: Loss --- 0.4547424018383026
Train batch 261: Loss --- 0.24604737758636475
Train batch 262: Loss --- 0.5307573676109314
Train batch 263: Loss --- 0.2691112756729126
Train batch 264: Loss --- 0.30632373690605164
Train batch 265: Loss --- 0.3481987416744232
Train batch 266: Loss --- 0.3465183973312378
Train batch 267: Loss --- 0.34313926100730896
Train batch 268: Loss --- 0.4392549991607666
Train batch 269: Loss --- 0.3317491114139557
Train batch 270: Loss --- 0.2356158047914505
Train batch 271: Loss --- 0.14696960151195526
Train batch 272: Loss --- 0.3717561960220337
Train batch 273: Loss --- 0.1730293184518814
Train batch 274: Loss --- 0.5086367726325989
Train batch 275: Loss --- 0.37486007809638977
Train batch 276: Loss --- 0.2744086682796478
Train batch 277: Loss --- 0.30632829666137695
Train batch 278: Loss --- 0.40852323174476624
Train batch 279: Loss --- 0.4411736726760864
Train batch 280: Loss --- 0.5922229886054993
Train batch 281: Loss --- 0.2899734079837799
Train batch 282: Loss --- 0.18866458535194397
Train batch 283: Loss --- 0.3217523992061615
Train batch 284: Loss --- 0.3973652720451355
Train batch 285: Loss --- 0.2876441478729248
Train batch 286: Loss --- 0.25586310029029846
Train batch 287: Loss --- 0.38749268651008606
Train batch 288: Loss --- 0.5570462346076965
Train batch 289: Loss --- 0.3197809159755707
Train batch 290: Loss --- 0.31181520223617554
Train batch 291: Loss --- 0.2771702706813812
Train batch 292: Loss --- 0.2052125185728073
Train batch 293: Loss --- 0.38668155670166016
Train batch 294: Loss --- 0.31153514981269836
Train batch 295: Loss --- 0.31266331672668457
Train batch 296: Loss --- 0.26738420128822327
Train batch 297: Loss --- 0.3948970139026642
Train batch 298: Loss --- 0.27408602833747864
Train batch 299: Loss --- 0.20823419094085693
Train batch 300: Loss --- 0.2655394673347473
Train batch 301: Loss --- 0.33581188321113586
Train batch 302: Loss --- 0.4671909511089325
Train batch 303: Loss --- 0.5039751529693604
Train batch 304: Loss --- 0.2512446939945221
Train batch 305: Loss --- 0.32655760645866394
Train batch 306: Loss --- 0.25965529680252075
Train batch 307: Loss --- 0.22252081334590912
Train batch 308: Loss --- 0.33670246601104736
Train batch 309: Loss --- 0.3064993619918823
Train batch 310: Loss --- 0.37389835715293884
Train batch 311: Loss --- 0.3135921359062195
Train batch 312: Loss --- 0.6378006935119629
Train batch 313: Loss --- 0.28120651841163635
Train batch 314: Loss --- 0.3735820949077606
Train batch 315: Loss --- 0.20628568530082703
Train batch 316: Loss --- 0.4408946931362152
Train batch 317: Loss --- 0.2860095500946045
Train batch 318: Loss --- 0.20234481990337372
Train batch 319: Loss --- 0.20135578513145447
Train batch 320: Loss --- 0.35638079047203064
Train batch 321: Loss --- 0.22166018187999725
Train batch 322: Loss --- 0.2617732286453247
Train batch 323: Loss --- 0.21039599180221558
Train batch 324: Loss --- 0.2664768099784851
Train batch 0: Loss --- 0.18277794122695923
Train batch 1: Loss --- 0.6193691492080688
Train batch 2: Loss --- 0.25923478603363037
Train batch 3: Loss --- 0.4126199781894684
Train batch 4: Loss --- 0.2352108657360077
Train batch 5: Loss --- 0.2680719792842865
Train batch 6: Loss --- 0.19206896424293518
Train batch 7: Loss --- 0.2808849513530731
Train batch 8: Loss --- 0.24270807206630707
Train batch 9: Loss --- 0.3081834018230438
Train batch 10: Loss --- 0.22203053534030914
Train batch 11: Loss --- 0.36846449971199036
Train batch 12: Loss --- 0.1574806272983551
Train batch 13: Loss --- 0.28107932209968567
Train batch 14: Loss --- 0.21866515278816223
Train batch 15: Loss --- 0.1423334777355194
Train batch 16: Loss --- 0.4003322422504425
Train batch 17: Loss --- 0.3059191405773163
Train batch 18: Loss --- 0.4068984091281891
Train batch 19: Loss --- 0.45585745573043823
Train batch 20: Loss --- 0.4585043489933014
Train batch 21: Loss --- 0.3278895318508148
Train batch 22: Loss --- 0.2783152163028717
Train batch 23: Loss --- 0.32003527879714966
Train batch 24: Loss --- 0.3248695135116577
Train batch 25: Loss --- 0.5260716080665588
Train batch 26: Loss --- 0.21543456614017487
Train batch 27: Loss --- 0.2410001903772354
Train batch 28: Loss --- 0.5076912045478821
Train batch 29: Loss --- 0.3717879354953766
Train batch 30: Loss --- 0.3777557909488678
Train batch 31: Loss --- 0.22271229326725006
Train batch 32: Loss --- 0.4939797520637512
Train batch 33: Loss --- 0.2667388916015625
Train batch 34: Loss --- 0.2645762264728546
Train batch 35: Loss --- 0.2288430780172348
Train batch 36: Loss --- 0.15986426174640656
Train batch 37: Loss --- 0.20580816268920898
Train batch 38: Loss --- 0.12446609139442444
Train batch 39: Loss --- 0.3384525775909424
Train batch 40: Loss --- 0.2127806693315506
Train batch 41: Loss --- 0.35040968656539917
Train batch 42: Loss --- 0.14666099846363068
Train batch 43: Loss --- 0.18985402584075928
Train batch 44: Loss --- 0.2975972294807434
Train batch 45: Loss --- 0.30805766582489014
Train batch 46: Loss --- 0.42213761806488037
Train batch 47: Loss --- 0.24828873574733734
Train batch 48: Loss --- 0.27099335193634033
Train batch 49: Loss --- 0.30647704005241394
Train batch 50: Loss --- 0.39659351110458374
Train batch 51: Loss --- 0.4259553849697113
Train batch 52: Loss --- 0.1291227787733078
Train batch 53: Loss --- 0.18163149058818817
Train batch 54: Loss --- 0.22148819267749786
Train batch 55: Loss --- 0.31620171666145325
Train batch 56: Loss --- 0.31007057428359985
Train batch 57: Loss --- 0.41728460788726807
Train batch 58: Loss --- 0.21950878202915192
Train batch 59: Loss --- 0.39298850297927856
Train batch 60: Loss --- 0.4170418083667755
Train batch 61: Loss --- 0.2312294989824295
Train batch 62: Loss --- 0.3731420040130615
Train batch 63: Loss --- 0.22336259484291077
Train batch 64: Loss --- 0.3159768879413605
Train batch 65: Loss --- 0.36485928297042847
Train batch 66: Loss --- 0.3285074234008789
Train batch 67: Loss --- 0.3228471279144287
Train batch 68: Loss --- 0.26278895139694214
Train batch 69: Loss --- 0.47855982184410095
Train batch 70: Loss --- 0.1401488184928894
Train batch 71: Loss --- 0.33330854773521423
Train batch 72: Loss --- 0.18872052431106567
Train batch 73: Loss --- 0.19458304345607758
Train batch 74: Loss --- 0.29968541860580444
Train batch 75: Loss --- 0.483611524105072
Train batch 76: Loss --- 0.18999847769737244
Train batch 77: Loss --- 0.2014121562242508
Train batch 78: Loss --- 0.3113104999065399
Train batch 79: Loss --- 0.2009192258119583
Train batch 80: Loss --- 0.3941556215286255
Train batch 81: Loss --- 0.25649914145469666
Train batch 82: Loss --- 0.2258482128381729
Train batch 83: Loss --- 0.3543112576007843
Train batch 84: Loss --- 0.3654462695121765
Train batch 85: Loss --- 0.24254962801933289
Train batch 86: Loss --- 0.2398463636636734
Train batch 87: Loss --- 0.4616048336029053
Train batch 88: Loss --- 0.2080318033695221
Train batch 89: Loss --- 0.29034408926963806
Train batch 90: Loss --- 0.3439319133758545
Train batch 91: Loss --- 0.3396362066268921
Train batch 92: Loss --- 0.258404940366745
Train batch 93: Loss --- 0.28667449951171875
Train batch 94: Loss --- 0.1410246044397354
Train batch 95: Loss --- 0.3358962833881378
Train batch 96: Loss --- 0.28179243206977844
Train batch 97: Loss --- 0.3394801616668701
Train batch 98: Loss --- 0.14697542786598206
Train batch 99: Loss --- 0.3485901951789856
Train batch 100: Loss --- 0.20213083922863007
Train batch 101: Loss --- 0.12476549297571182
Train batch 102: Loss --- 0.17028197646141052
Train batch 103: Loss --- 0.4018247723579407
Train batch 104: Loss --- 0.20642271637916565
Train batch 105: Loss --- 0.34705907106399536
Train batch 106: Loss --- 0.4589668810367584
Train batch 107: Loss --- 0.2075817883014679
Train batch 108: Loss --- 0.21530567109584808
Train batch 109: Loss --- 0.2701931595802307
Train batch 110: Loss --- 0.18391050398349762
Train batch 111: Loss --- 0.20477716624736786
Train batch 112: Loss --- 0.14534981548786163
Train batch 113: Loss --- 0.2591330409049988
Train batch 114: Loss --- 0.255105197429657
Train batch 115: Loss --- 0.2746938467025757
Train batch 116: Loss --- 0.34738773107528687
Train batch 117: Loss --- 0.19201555848121643
Train batch 118: Loss --- 0.25338491797447205
Train batch 119: Loss --- 0.4221635162830353
Train batch 120: Loss --- 0.38459521532058716
Train batch 121: Loss --- 0.18141378462314606
Traceback (most recent call last):
  File "tools/train.py", line 35, in <module>
    train_model(epochs, criterion, optimizer)
  File "tools/train.py", line 18, in train_model
    for batch_idx, (data, labels) in enumerate(train_loader):
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 399, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 399, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 231, in __getitem__
    sample = self.transform(sample)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 354, in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torchvision/transforms/functional.py", line 467, in resize
    return F_pil.resize(img, size=output_size, interpolation=pil_interpolation)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torchvision/transforms/_functional_pil.py", line 250, in resize
    return img.resize(tuple(size[::-1]), interpolation)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/PIL/Image.py", line 2200, in resize
    return self._new(self.im.resize(size, resample, box))
KeyboardInterrupt
Train batch 122: Loss --- 0.24712038040161133