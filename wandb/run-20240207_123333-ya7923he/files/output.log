Train batch 0: Loss --- 0.7008019089698792
Train batch 1: Loss --- 0.7041002511978149
Train batch 2: Loss --- 0.6626590490341187
Train batch 3: Loss --- 0.6745758056640625
Train batch 4: Loss --- 0.6468172669410706
Train batch 5: Loss --- 0.6047592163085938
Train batch 6: Loss --- 0.6194943189620972
Train batch 7: Loss --- 0.6399657726287842
Train batch 8: Loss --- 0.5949618220329285
Train batch 9: Loss --- 0.5613126158714294
Train batch 10: Loss --- 0.5707306265830994
Train batch 11: Loss --- 0.6224411725997925
Train batch 12: Loss --- 0.6245286464691162
Train batch 13: Loss --- 0.5535777807235718
Train batch 14: Loss --- 0.5430099368095398
Train batch 15: Loss --- 0.5557267069816589
Train batch 16: Loss --- 0.5434786081314087
Train batch 17: Loss --- 0.4856453835964203
Train batch 18: Loss --- 0.5222975611686707
Train batch 19: Loss --- 0.6734707355499268
Train batch 20: Loss --- 0.41834935545921326
Train batch 21: Loss --- 0.46971842646598816
Train batch 22: Loss --- 0.490117609500885
Train batch 23: Loss --- 0.5435996651649475
Train batch 24: Loss --- 0.37201422452926636
Train batch 25: Loss --- 0.5983988642692566
Train batch 26: Loss --- 0.4291187524795532
Train batch 27: Loss --- 0.4266991913318634
Train batch 28: Loss --- 0.44448357820510864
Train batch 29: Loss --- 0.36336731910705566
Train batch 30: Loss --- 0.594173789024353
Train batch 31: Loss --- 0.5537221431732178
Train batch 32: Loss --- 0.5493364930152893
Train batch 33: Loss --- 0.7340573072433472
Train batch 34: Loss --- 0.39912664890289307
Train batch 35: Loss --- 0.6257575750350952
Train batch 36: Loss --- 0.3456944227218628
Train batch 37: Loss --- 0.7529032826423645
Train batch 38: Loss --- 0.37697353959083557
Train batch 39: Loss --- 0.5577882528305054
Train batch 40: Loss --- 0.6511656641960144
Train batch 41: Loss --- 0.39257529377937317
Train batch 42: Loss --- 0.5132091045379639
Train batch 43: Loss --- 0.7393953800201416
Train batch 44: Loss --- 0.48537516593933105
Train batch 45: Loss --- 0.5645362138748169
Train batch 46: Loss --- 0.5194585919380188
Train batch 47: Loss --- 0.5337849855422974
Train batch 48: Loss --- 0.3645516037940979
Train batch 49: Loss --- 0.49241724610328674
Train batch 50: Loss --- 0.47339028120040894
Train batch 51: Loss --- 0.4650363326072693
Train batch 52: Loss --- 0.40095600485801697
Train batch 53: Loss --- 0.4302390217781067
Train batch 54: Loss --- 0.3384647071361542
Train batch 55: Loss --- 0.45941606163978577
Train batch 56: Loss --- 0.6025574207305908
Train batch 57: Loss --- 0.5405673980712891
Train batch 58: Loss --- 0.513039231300354
Train batch 59: Loss --- 0.48576873540878296
Train batch 60: Loss --- 0.4647776484489441
Train batch 61: Loss --- 0.38122743368148804
Train batch 62: Loss --- 0.476778507232666
Train batch 63: Loss --- 0.33239251375198364
Train batch 64: Loss --- 0.3728584945201874
Train batch 65: Loss --- 0.5114051699638367
Train batch 66: Loss --- 0.4076755940914154
Train batch 67: Loss --- 0.3635721206665039
Train batch 68: Loss --- 0.46777719259262085
Train batch 69: Loss --- 0.38754329085350037
Train batch 70: Loss --- 0.3123297095298767
Train batch 71: Loss --- 0.40187543630599976
Train batch 72: Loss --- 0.5744015574455261
Train batch 73: Loss --- 0.48435938358306885
Train batch 74: Loss --- 0.31473416090011597
Train batch 75: Loss --- 0.30880120396614075
Train batch 76: Loss --- 0.4488932490348816
Train batch 77: Loss --- 0.675122857093811
Train batch 78: Loss --- 0.4449198544025421
Train batch 79: Loss --- 0.36690178513526917
Train batch 80: Loss --- 0.6306279301643372
Train batch 81: Loss --- 0.3464449346065521
Train batch 82: Loss --- 0.4415090084075928
Train batch 83: Loss --- 0.4759787321090698
Train batch 84: Loss --- 0.4271528422832489
Train batch 85: Loss --- 0.5820158123970032
Train batch 86: Loss --- 0.3640103340148926
Train batch 87: Loss --- 0.3544866144657135
Train batch 88: Loss --- 0.4764314591884613
Train batch 89: Loss --- 0.5044780969619751
Train batch 90: Loss --- 0.33124637603759766
Train batch 91: Loss --- 0.6038188934326172
Train batch 92: Loss --- 0.3913852274417877
Train batch 93: Loss --- 0.3501877784729004
Train batch 94: Loss --- 0.3551713526248932
Train batch 95: Loss --- 0.3764578700065613
Train batch 96: Loss --- 0.5420976281166077
Train batch 97: Loss --- 0.503957986831665
Train batch 98: Loss --- 0.6010333299636841
Train batch 99: Loss --- 0.33077293634414673
Train batch 100: Loss --- 0.33866962790489197
Train batch 101: Loss --- 0.6163683533668518
Train batch 102: Loss --- 0.46660906076431274
Train batch 103: Loss --- 0.45754721760749817
Train batch 104: Loss --- 0.3046213984489441
Train batch 105: Loss --- 0.4396477937698364
Train batch 106: Loss --- 0.3507786989212036
Train batch 107: Loss --- 0.45904961228370667
Train batch 108: Loss --- 0.3037266135215759
Train batch 109: Loss --- 0.2881731390953064
Train batch 110: Loss --- 0.44931164383888245
Train batch 111: Loss --- 0.3707428574562073
Train batch 112: Loss --- 0.3209640085697174
Train batch 113: Loss --- 0.3420153260231018
Train batch 114: Loss --- 0.41989123821258545
Train batch 115: Loss --- 0.39563634991645813
Train batch 116: Loss --- 0.5493413209915161
Train batch 117: Loss --- 0.453363835811615
Train batch 118: Loss --- 0.5224440693855286
Train batch 119: Loss --- 0.39189937710762024
Train batch 120: Loss --- 0.3401282727718353
Train batch 121: Loss --- 0.2708529829978943
Train batch 122: Loss --- 0.26843535900115967
Train batch 123: Loss --- 0.5521321892738342
Train batch 124: Loss --- 0.3222876787185669
Train batch 125: Loss --- 0.37155699729919434
Train batch 126: Loss --- 0.211564302444458
Train batch 127: Loss --- 0.23227538168430328
Train batch 128: Loss --- 0.23077094554901123
Train batch 129: Loss --- 0.3615574836730957
Train batch 130: Loss --- 0.46297380328178406
Train batch 131: Loss --- 0.2622995674610138
Train batch 132: Loss --- 0.4313712418079376
Train batch 133: Loss --- 0.41203153133392334
Train batch 134: Loss --- 0.3599053621292114
Train batch 135: Loss --- 0.3743223249912262
Train batch 136: Loss --- 0.4359981119632721
Train batch 137: Loss --- 0.23775357007980347
Train batch 138: Loss --- 0.4337359666824341
Train batch 139: Loss --- 0.30885422229766846
Train batch 140: Loss --- 0.7222046256065369
Train batch 141: Loss --- 0.3547307252883911
Train batch 142: Loss --- 0.6752005815505981
Train batch 143: Loss --- 0.3788243234157562
Train batch 144: Loss --- 0.3760673999786377
Train batch 145: Loss --- 0.4727398753166199
Train batch 146: Loss --- 0.2803603410720825
Train batch 147: Loss --- 0.3436468541622162
Train batch 148: Loss --- 0.3152022063732147
Train batch 149: Loss --- 0.6109523177146912
Train batch 150: Loss --- 0.40006521344184875
Train batch 151: Loss --- 0.39754363894462585
Train batch 152: Loss --- 0.3751868009567261
Train batch 153: Loss --- 0.41058871150016785
Train batch 154: Loss --- 0.32535380125045776
Train batch 155: Loss --- 0.4347631335258484
Train batch 156: Loss --- 0.2987973690032959
Train batch 157: Loss --- 0.43494945764541626
Train batch 158: Loss --- 0.5859496593475342
Train batch 159: Loss --- 0.45238643884658813
Train batch 160: Loss --- 0.37827181816101074
Train batch 161: Loss --- 0.3836084306240082
Train batch 162: Loss --- 0.4638393521308899
Train batch 163: Loss --- 0.3895469903945923
Train batch 164: Loss --- 0.5765852332115173
Train batch 165: Loss --- 0.33668142557144165
Train batch 166: Loss --- 0.2873091995716095
Train batch 167: Loss --- 0.4312022626399994
Train batch 168: Loss --- 0.3775884509086609
Train batch 169: Loss --- 0.38148775696754456
Train batch 170: Loss --- 0.43164822459220886
Train batch 171: Loss --- 0.2678220272064209
Train batch 172: Loss --- 0.39455825090408325
Train batch 173: Loss --- 0.3661726713180542
Train batch 174: Loss --- 0.4697386622428894
Train batch 175: Loss --- 0.36388614773750305
Train batch 176: Loss --- 0.27865055203437805
Train batch 177: Loss --- 0.3588593900203705
Train batch 178: Loss --- 0.43650469183921814
Train batch 179: Loss --- 0.3665536642074585
Train batch 180: Loss --- 0.22538654506206512
Train batch 181: Loss --- 0.2635580897331238
Train batch 182: Loss --- 0.29380613565444946
Train batch 183: Loss --- 0.4017621576786041
Train batch 184: Loss --- 0.45512014627456665
Train batch 185: Loss --- 0.28992345929145813
Train batch 186: Loss --- 0.29384946823120117
Train batch 187: Loss --- 0.24113962054252625
Train batch 188: Loss --- 0.2863468825817108
Train batch 189: Loss --- 0.3819786608219147
Train batch 190: Loss --- 0.40241363644599915
Train batch 191: Loss --- 0.37773698568344116
Train batch 192: Loss --- 0.42769208550453186
Train batch 193: Loss --- 0.5283243060112
Train batch 194: Loss --- 0.5524422526359558
Train batch 195: Loss --- 0.2879185378551483
Train batch 196: Loss --- 0.4028572142124176
Train batch 197: Loss --- 0.3442261517047882
Train batch 198: Loss --- 0.266362726688385
Train batch 199: Loss --- 0.42512047290802
Train batch 200: Loss --- 0.3961258828639984
Train batch 201: Loss --- 0.45782768726348877
Train batch 202: Loss --- 0.49554601311683655
Train batch 203: Loss --- 0.33640778064727783
Train batch 204: Loss --- 0.32754990458488464
Train batch 205: Loss --- 0.28307539224624634
Train batch 206: Loss --- 0.38655123114585876
Train batch 207: Loss --- 0.40625905990600586
Train batch 208: Loss --- 0.41500967741012573
Train batch 209: Loss --- 0.2930396497249603
Train batch 210: Loss --- 0.2431432604789734
Train batch 211: Loss --- 0.3311867117881775
Train batch 212: Loss --- 0.18974319100379944
Train batch 213: Loss --- 0.32511430978775024
Train batch 214: Loss --- 0.351743221282959
Train batch 215: Loss --- 0.2340802401304245
Train batch 216: Loss --- 0.25206565856933594
Train batch 217: Loss --- 0.3119233250617981
Train batch 218: Loss --- 0.3519321382045746
Train batch 219: Loss --- 0.5448424220085144
Train batch 220: Loss --- 0.29324230551719666
Train batch 221: Loss --- 0.27208447456359863
Train batch 222: Loss --- 0.39245161414146423
Train batch 223: Loss --- 0.3021599352359772
Train batch 224: Loss --- 0.3836838901042938
Train batch 225: Loss --- 0.18737126886844635
Train batch 226: Loss --- 0.37441566586494446
Train batch 227: Loss --- 0.516502320766449
Train batch 228: Loss --- 0.2255668044090271
Train batch 229: Loss --- 0.40040090680122375
Train batch 230: Loss --- 0.5703082084655762
Train batch 231: Loss --- 0.3815326690673828
Train batch 232: Loss --- 0.22193609178066254
Train batch 233: Loss --- 0.25332462787628174
Train batch 234: Loss --- 0.25218772888183594
Train batch 235: Loss --- 0.37758103013038635
Train batch 236: Loss --- 0.2717067003250122
Train batch 237: Loss --- 0.34710273146629333
Train batch 238: Loss --- 0.3318030536174774
Train batch 239: Loss --- 0.6970372200012207
Train batch 240: Loss --- 0.2731393277645111
Train batch 241: Loss --- 0.3729848265647888
Train batch 242: Loss --- 0.4057113826274872
Train batch 243: Loss --- 0.2634267210960388
Train batch 244: Loss --- 0.38630425930023193
Train batch 245: Loss --- 0.24632175266742706
Train batch 246: Loss --- 0.30033597350120544
Train batch 247: Loss --- 0.2791822850704193
Train batch 248: Loss --- 0.41592898964881897
Train batch 249: Loss --- 0.38474857807159424
Train batch 250: Loss --- 0.625900149345398
Train batch 251: Loss --- 0.43946173787117004
Train batch 252: Loss --- 0.17301109433174133
Train batch 253: Loss --- 0.4611983001232147
Train batch 254: Loss --- 0.19783389568328857
Train batch 255: Loss --- 0.40239623188972473
Train batch 256: Loss --- 0.29779261350631714
Train batch 257: Loss --- 0.31652727723121643
Train batch 258: Loss --- 0.22550490498542786
Train batch 259: Loss --- 0.6249819993972778
Train batch 260: Loss --- 0.28735992312431335
Train batch 261: Loss --- 0.34782373905181885
Train batch 262: Loss --- 0.3922547996044159
Train batch 263: Loss --- 0.3681434988975525
Train batch 264: Loss --- 0.28989753127098083
Train batch 265: Loss --- 0.31490710377693176
Train batch 266: Loss --- 0.2803560793399811
Train batch 267: Loss --- 0.35750383138656616
Train batch 268: Loss --- 0.518905758857727
Train batch 269: Loss --- 0.3462528586387634
Train batch 270: Loss --- 0.3271268904209137
Train batch 271: Loss --- 0.28928637504577637
Train batch 272: Loss --- 0.4361658990383148
Train batch 273: Loss --- 0.35024523735046387
Train batch 274: Loss --- 0.27122166752815247
Train batch 275: Loss --- 0.25840380787849426
Train batch 276: Loss --- 0.2825920581817627
Train batch 277: Loss --- 0.3003864288330078
Train batch 278: Loss --- 0.36057427525520325
Train batch 279: Loss --- 0.3765701949596405
Train batch 280: Loss --- 0.2364237904548645
Train batch 281: Loss --- 0.2709318697452545
Train batch 282: Loss --- 0.27104276418685913
Train batch 283: Loss --- 0.6259822845458984
Train batch 284: Loss --- 0.24201051890850067
Train batch 285: Loss --- 0.5709974765777588
Train batch 286: Loss --- 0.5331044793128967
Train batch 287: Loss --- 0.37541326880455017
Train batch 288: Loss --- 0.30902913212776184
Train batch 289: Loss --- 0.19501884281635284
Train batch 290: Loss --- 0.15066269040107727
Train batch 291: Loss --- 0.30420324206352234
Train batch 292: Loss --- 0.34395551681518555
Train batch 293: Loss --- 0.2698214054107666
Train batch 294: Loss --- 0.3663195073604584
Train batch 295: Loss --- 0.28004997968673706
Train batch 296: Loss --- 0.35816386342048645
Train batch 297: Loss --- 0.324389785528183
Train batch 298: Loss --- 0.20455127954483032
Train batch 299: Loss --- 0.35936906933784485
Train batch 300: Loss --- 0.2478916198015213
Train batch 301: Loss --- 0.324329674243927
Train batch 302: Loss --- 0.31039127707481384
Train batch 303: Loss --- 0.26187238097190857
Train batch 304: Loss --- 0.25791388750076294
Train batch 305: Loss --- 0.296154648065567
Train batch 306: Loss --- 0.4318450093269348
Train batch 307: Loss --- 0.45673391222953796
Train batch 308: Loss --- 0.3801501989364624
Train batch 309: Loss --- 0.32539522647857666
Train batch 310: Loss --- 0.37642306089401245
Train batch 311: Loss --- 0.24975988268852234
Train batch 312: Loss --- 0.4956331253051758
Train batch 313: Loss --- 0.39834800362586975
Train batch 314: Loss --- 0.5237659215927124
Train batch 315: Loss --- 0.25708481669425964
Train batch 316: Loss --- 0.16816118359565735
Train batch 317: Loss --- 0.371011346578598
Train batch 318: Loss --- 0.25942462682724
Train batch 319: Loss --- 0.19804647564888
Train batch 320: Loss --- 0.3048313856124878
Train batch 321: Loss --- 0.18202736973762512
Train batch 322: Loss --- 0.35795605182647705
Train batch 323: Loss --- 0.3398410379886627
Train batch 324: Loss --- 0.3118572235107422
Train batch 0: Loss --- 0.4101591110229492
Train batch 1: Loss --- 0.3810485303401947
Train batch 2: Loss --- 0.21551960706710815
Train batch 3: Loss --- 0.2127194106578827
Train batch 4: Loss --- 0.3400125205516815
Train batch 5: Loss --- 0.2999633252620697
Train batch 6: Loss --- 0.2600507438182831
Train batch 7: Loss --- 0.33480560779571533
Train batch 8: Loss --- 0.1918329894542694
Train batch 9: Loss --- 0.1511659324169159
Train batch 10: Loss --- 0.14931455254554749
Train batch 11: Loss --- 0.2728736996650696
Train batch 12: Loss --- 0.15523764491081238
Train batch 13: Loss --- 0.16448643803596497
Train batch 14: Loss --- 0.28572535514831543
Train batch 15: Loss --- 0.2285897135734558
Train batch 16: Loss --- 0.550662636756897
Train batch 17: Loss --- 0.33670973777770996
Train batch 18: Loss --- 0.33556902408599854
Train batch 19: Loss --- 0.41796499490737915
Train batch 20: Loss --- 0.24211743474006653
Train batch 21: Loss --- 0.4235938787460327
Train batch 22: Loss --- 0.20699910819530487
Train batch 23: Loss --- 0.17835237085819244
Train batch 24: Loss --- 0.37103477120399475
Train batch 25: Loss --- 0.27554163336753845
Train batch 26: Loss --- 0.326418936252594
Train batch 27: Loss --- 0.4166175127029419
Train batch 28: Loss --- 0.28111761808395386
Train batch 29: Loss --- 0.19029869139194489
Train batch 30: Loss --- 0.2052261233329773
Train batch 31: Loss --- 0.3842596709728241
Train batch 32: Loss --- 0.1780877560377121
Train batch 33: Loss --- 0.43071940541267395
Train batch 34: Loss --- 0.33305421471595764
Train batch 35: Loss --- 0.2846207916736603
Train batch 36: Loss --- 0.21103906631469727
Train batch 37: Loss --- 0.4285239577293396
Train batch 38: Loss --- 0.29845544695854187
Train batch 39: Loss --- 0.42590829730033875
Train batch 40: Loss --- 0.23815353214740753
Train batch 41: Loss --- 0.23286114633083344
Train batch 42: Loss --- 0.3610229790210724
Train batch 43: Loss --- 0.20377640426158905
Train batch 44: Loss --- 0.23364581167697906
Train batch 45: Loss --- 0.2450712025165558
Train batch 46: Loss --- 0.2566596269607544
Train batch 47: Loss --- 0.2511577904224396
Train batch 48: Loss --- 0.2640383243560791
Traceback (most recent call last):
  File "tools/train.py", line 35, in <module>
    train_model(epochs, criterion, optimizer)
  File "tools/train.py", line 19, in train_model
    for batch_idx, (data, labels) in enumerate(train_loader):
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 399, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 399, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 229, in __getitem__
    sample = self.loader(path)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 268, in default_loader
    return pil_loader(path)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torchvision/datasets/folder.py", line 248, in pil_loader
    return img.convert("RGB")
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/PIL/Image.py", line 922, in convert
    self.load()
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/PIL/ImageFile.py", line 291, in load
    n, err_code = decoder.decode(b)
KeyboardInterrupt