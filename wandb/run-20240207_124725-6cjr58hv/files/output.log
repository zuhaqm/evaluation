Train batch 0: Loss --- 0.7264825701713562
Train batch 1: Loss --- 0.6984444856643677
Train batch 2: Loss --- 0.7011966705322266
Train batch 3: Loss --- 0.6824473738670349
Train batch 4: Loss --- 0.6612128019332886
Train batch 5: Loss --- 0.6485252976417542
Train batch 6: Loss --- 0.6257485151290894
Train batch 7: Loss --- 0.639622151851654
Train batch 8: Loss --- 0.5916228890419006
Train batch 9: Loss --- 0.6734159588813782
Train batch 10: Loss --- 0.6105177998542786
Train batch 11: Loss --- 0.5569403171539307
Train batch 12: Loss --- 0.6256884932518005
Train batch 13: Loss --- 0.6075528860092163
Train batch 14: Loss --- 0.5891870856285095
Train batch 15: Loss --- 0.5526106953620911
Train batch 16: Loss --- 0.5800122618675232
Train batch 17: Loss --- 0.5300028324127197
Train batch 18: Loss --- 0.465351939201355
Train batch 19: Loss --- 0.5857606530189514
Train batch 20: Loss --- 0.45525825023651123
Train batch 21: Loss --- 0.4633205235004425
Train batch 22: Loss --- 0.4635346233844757
Train batch 23: Loss --- 0.5590101480484009
Train batch 24: Loss --- 0.3911987841129303
Train batch 25: Loss --- 0.5243717432022095
Train batch 26: Loss --- 0.4687623083591461
Train batch 27: Loss --- 0.570743203163147
Train batch 28: Loss --- 0.5145211815834045
Train batch 29: Loss --- 0.4986850619316101
Train batch 30: Loss --- 0.5468688011169434
Train batch 31: Loss --- 0.5337537527084351
Train batch 32: Loss --- 0.6083836555480957
Train batch 33: Loss --- 0.5706993937492371
Train batch 34: Loss --- 0.46382978558540344
Train batch 35: Loss --- 0.774058997631073
Train batch 36: Loss --- 0.3842867910861969
Train batch 37: Loss --- 0.642188310623169
Train batch 38: Loss --- 0.3500799536705017
Train batch 39: Loss --- 0.4968237280845642
Train batch 40: Loss --- 0.5166530013084412
Train batch 41: Loss --- 0.5407109260559082
Train batch 42: Loss --- 0.5349484086036682
Train batch 43: Loss --- 0.41914102435112
Train batch 44: Loss --- 0.3647236227989197
Train batch 45: Loss --- 0.43232324719429016
Train batch 46: Loss --- 0.6715304255485535
Train batch 47: Loss --- 0.6179144978523254
Train batch 48: Loss --- 0.6476055979728699
Train batch 49: Loss --- 0.5113933682441711
Train batch 50: Loss --- 0.4504852890968323
Train batch 51: Loss --- 0.4800523519515991
Train batch 52: Loss --- 0.46880412101745605
Train batch 53: Loss --- 0.4303067624568939
Train batch 54: Loss --- 0.44385868310928345
Train batch 55: Loss --- 0.4124452471733093
Train batch 56: Loss --- 0.48475223779678345
Train batch 57: Loss --- 0.5641856789588928
Train batch 58: Loss --- 0.6218522787094116
Train batch 59: Loss --- 0.4171840250492096
Train batch 60: Loss --- 0.44164296984672546
Train batch 61: Loss --- 0.5026254653930664
Train batch 62: Loss --- 0.35754066705703735
Train batch 63: Loss --- 0.5245658755302429
Train batch 64: Loss --- 0.6143060922622681
Train batch 65: Loss --- 0.5352579355239868
Train batch 66: Loss --- 0.35808005928993225
Train batch 67: Loss --- 0.3671093285083771
Train batch 68: Loss --- 0.4799771308898926
Train batch 69: Loss --- 0.343391090631485
Train batch 70: Loss --- 0.48982030153274536
Train batch 71: Loss --- 0.5824148058891296
Train batch 72: Loss --- 0.3747164011001587
Train batch 73: Loss --- 0.47253507375717163
Train batch 74: Loss --- 0.5256285071372986
Train batch 75: Loss --- 0.5449967384338379
Train batch 76: Loss --- 0.4429772198200226
Train batch 77: Loss --- 0.3990977704524994
Train batch 78: Loss --- 0.5393174886703491
Train batch 79: Loss --- 0.3983258306980133
Train batch 80: Loss --- 0.460965633392334
Train batch 81: Loss --- 0.3643222153186798
Train batch 82: Loss --- 0.5795069336891174
Train batch 83: Loss --- 0.44226399064064026
Train batch 84: Loss --- 0.39274320006370544
Train batch 85: Loss --- 0.4719809591770172
Train batch 86: Loss --- 0.5420172810554504
Train batch 87: Loss --- 0.3117188513278961
Train batch 88: Loss --- 0.4577018618583679
Train batch 89: Loss --- 0.42836982011795044
Train batch 90: Loss --- 0.4602389931678772
Train batch 91: Loss --- 0.37376323342323303
Train batch 92: Loss --- 0.4747900366783142
Train batch 93: Loss --- 0.2424589842557907
Train batch 94: Loss --- 0.5622279644012451
Train batch 95: Loss --- 0.6719738245010376
Train batch 96: Loss --- 0.5843367576599121
Train batch 97: Loss --- 0.5163113474845886
Train batch 98: Loss --- 0.44757625460624695
Train batch 99: Loss --- 0.3394823670387268
Train batch 100: Loss --- 0.2979830801486969
Train batch 101: Loss --- 0.6164931654930115
Train batch 102: Loss --- 0.4093480408191681
Train batch 103: Loss --- 0.3742262125015259
Train batch 104: Loss --- 0.34923413395881653
Train batch 105: Loss --- 0.4370574951171875
Train batch 106: Loss --- 0.46424588561058044
Train batch 107: Loss --- 0.6285500526428223
Train batch 108: Loss --- 0.37285834550857544
Train batch 109: Loss --- 0.30596834421157837
Train batch 110: Loss --- 0.5524185299873352
Train batch 111: Loss --- 0.4369458258152008
Train batch 112: Loss --- 0.454082190990448
Train batch 113: Loss --- 0.47476762533187866
Train batch 114: Loss --- 0.3687240481376648
Train batch 115: Loss --- 0.3877541124820709
Train batch 116: Loss --- 0.4892445504665375
Train batch 117: Loss --- 0.3699883222579956
Train batch 118: Loss --- 0.3789480924606323
Train batch 119: Loss --- 0.3979153633117676
Train batch 120: Loss --- 0.4044884741306305
Train batch 121: Loss --- 0.47464025020599365
Train batch 122: Loss --- 0.3239850699901581
Train batch 123: Loss --- 0.40105950832366943
Train batch 124: Loss --- 0.46918153762817383
Train batch 125: Loss --- 0.34258705377578735
Train batch 126: Loss --- 0.5277320146560669
Train batch 127: Loss --- 0.35710200667381287
Train batch 128: Loss --- 0.26987168192863464
Train batch 129: Loss --- 0.567891538143158
Train batch 130: Loss --- 0.29150176048278815
Train batch 131: Loss --- 0.34749212861061096
Train batch 132: Loss --- 0.24743422865867615
Train batch 133: Loss --- 0.5418420433998108
Train batch 134: Loss --- 0.3218873143196106
Train batch 135: Loss --- 0.3759676516056061
Train batch 136: Loss --- 0.3336515426635742
Train batch 137: Loss --- 0.35655444860458374
Train batch 138: Loss --- 0.515516996383667
Train batch 139: Loss --- 0.54939275979995735
Train batch 140: Loss --- 0.47409191727638245
Train batch 141: Loss --- 0.47087574005126953
Train batch 142: Loss --- 0.29076632857322693
Train batch 143: Loss --- 0.5142974853515625
Train batch 144: Loss --- 0.26150622963905334
Train batch 145: Loss --- 0.45566633343696594
Train batch 146: Loss --- 0.38513892889022827
Train batch 148: Loss --- 0.41197478771209717
Train batch 149: Loss --- 0.28106018900871277
Train batch 150: Loss --- 0.3193545341491699
Train batch 151: Loss --- 0.46868109703063965
Train batch 152: Loss --- 0.3657686114311218
Train batch 153: Loss --- 0.37851905822753906
Train batch 154: Loss --- 0.4975927174091339
Train batch 155: Loss --- 0.4053558111190796
Train batch 157: Loss --- 0.34507927298545847
Train batch 158: Loss --- 0.30997955799102783
Train batch 159: Loss --- 0.3463672697544098
Train batch 160: Loss --- 0.55230712890625
Train batch 161: Loss --- 0.31102198362350464
Train batch 162: Loss --- 0.5942676067352295
Train batch 163: Loss --- 0.48004770278930664
Train batch 164: Loss --- 0.3697480857372284
Train batch 166: Loss --- 0.38318607211112976
Train batch 167: Loss --- 0.3258746564388275
Train batch 168: Loss --- 0.43398842215538025
Train batch 169: Loss --- 0.33214038610458374
Train batch 170: Loss --- 0.5949251651763916
Train batch 171: Loss --- 0.394919753074646
Train batch 172: Loss --- 0.3064534664154053
Train batch 173: Loss --- 0.34914788603782654
Train batch 175: Loss --- 0.27578949928283696
Train batch 176: Loss --- 0.28581440448760986
Train batch 177: Loss --- 0.3331838548183441
Train batch 178: Loss --- 0.3427915871143341
Train batch 179: Loss --- 0.3176518380641937
Train batch 180: Loss --- 0.4129961133003235
Train batch 181: Loss --- 0.40131843090057373
Train batch 182: Loss --- 0.6254106760025024
Train batch 184: Loss --- 0.23067483305931096
Train batch 185: Loss --- 0.44276079535484314
Train batch 186: Loss --- 0.4149623513221741
Train batch 187: Loss --- 0.3467070758342743
Train batch 188: Loss --- 0.2518746554851532
Train batch 189: Loss --- 0.46651262044906616
Train batch 190: Loss --- 0.40918803215026855
Train batch 193: Loss --- 0.56063210964202886
Train batch 194: Loss --- 0.3889080882072449
Train batch 195: Loss --- 0.24241062998771667
Train batch 196: Loss --- 0.26807865500450134
Train batch 197: Loss --- 0.4049028754234314
Train batch 198: Loss --- 0.4423137903213501
Train batch 199: Loss --- 0.33014822006225586
Train batch 200: Loss --- 0.2925353944301605
Train batch 202: Loss --- 0.39407357573509216
Train batch 203: Loss --- 0.31852465867996216
Train batch 204: Loss --- 0.29289498925209045
Train batch 205: Loss --- 0.2666148543357849
Train batch 206: Loss --- 0.3727863132953644
Train batch 207: Loss --- 0.2807679772377014
Train batch 208: Loss --- 0.34910494089126587
Train batch 209: Loss --- 0.5239193439483643
Train batch 211: Loss --- 0.31580042839050293
Train batch 212: Loss --- 0.26864752173423767
Train batch 213: Loss --- 0.34287339448928833
Train batch 214: Loss --- 0.37227585911750793
Train batch 215: Loss --- 0.3437049388885498
Train batch 216: Loss --- 0.25503018498420715
Train batch 217: Loss --- 0.4317733943462372
Train batch 218: Loss --- 0.5372728109359741
Train batch 220: Loss --- 0.50649166107177733
Train batch 221: Loss --- 0.27115070819854736
Train batch 222: Loss --- 0.4151839017868042
Train batch 223: Loss --- 0.3438226580619812
Train batch 224: Loss --- 0.466544508934021
Train batch 225: Loss --- 0.335440456867218
Train batch 226: Loss --- 0.3529060184955597
Train batch 227: Loss --- 0.22345399856567383
Train batch 228: Loss --- 0.42419129610061646
Train batch 229: Loss --- 0.39382368326187134
Train batch 230: Loss --- 0.3966219127178192
Train batch 231: Loss --- 0.28001829981803894
Train batch 232: Loss --- 0.2990886867046356
Train batch 233: Loss --- 0.20654931664466858
Train batch 234: Loss --- 0.40404048562049866
Train batch 235: Loss --- 0.4224826395511627
Train batch 236: Loss --- 0.5525816679000854
Train batch 237: Loss --- 0.3148377537727356
Train batch 238: Loss --- 0.44398963451385534
Train batch 239: Loss --- 0.2423059046268463
Train batch 240: Loss --- 0.3430999517440796
Train batch 241: Loss --- 0.444303423166275
Train batch 242: Loss --- 0.4322269856929779
Train batch 243: Loss --- 0.2684989273548126
Train batch 244: Loss --- 0.3754079043865204
Train batch 245: Loss --- 0.1959005743265152
Train batch 246: Loss --- 0.4237309694290161
Train batch 247: Loss --- 0.30946454405784607
Train batch 248: Loss --- 0.24703696370124817
Train batch 249: Loss --- 0.3051771819591522
Train batch 250: Loss --- 0.26623785495758057
Train batch 251: Loss --- 0.4489719867706299
Train batch 252: Loss --- 0.2617015540599823
Train batch 253: Loss --- 0.3687032461166382
Train batch 254: Loss --- 0.36644303798675537
Train batch 256: Loss --- 0.40000051259994507
Train batch 257: Loss --- 0.33659660816192627
Train batch 258: Loss --- 0.4173826575279236
Train batch 259: Loss --- 0.31655845046043396
Train batch 260: Loss --- 0.19233180582523346
Train batch 261: Loss --- 0.3175770044326782
Train batch 262: Loss --- 0.33326494693756104
Train batch 263: Loss --- 0.20922477543354034
Train batch 265: Loss --- 0.24127061665058136
Train batch 266: Loss --- 0.3358112573623657
Train batch 267: Loss --- 0.21197231113910675
Train batch 268: Loss --- 0.16697284579277039
Train batch 269: Loss --- 0.3781977891921997
Train batch 270: Loss --- 0.30990952253341675
Train batch 271: Loss --- 0.46782630681991577
Train batch 272: Loss --- 0.40341395139694214
Train batch 274: Loss --- 0.15689243376255035
Train batch 275: Loss --- 0.3601808249950409
Train batch 276: Loss --- 0.3467654287815094
Train batch 277: Loss --- 0.33665725588798523
Train batch 278: Loss --- 0.32419466972351074
Train batch 279: Loss --- 0.31768831610679626
Train batch 280: Loss --- 0.20904949307441711
Train batch 281: Loss --- 0.37145915627479553
Train batch 283: Loss --- 0.40218275785446167
Train batch 284: Loss --- 0.2989707887172699
Train batch 285: Loss --- 0.176661878824234
Train batch 286: Loss --- 0.2513607442378998
Train batch 287: Loss --- 0.39957377314567566
Train batch 288: Loss --- 0.26677054166793823
Train batch 289: Loss --- 0.2075289934873581
Train batch 290: Loss --- 0.5192446708679199
Train batch 292: Loss --- 0.19147978723049164
Train batch 293: Loss --- 0.3669208288192749
Train batch 294: Loss --- 0.22436408698558807
Train batch 295: Loss --- 0.3684859275817871
Train batch 296: Loss --- 0.4175988435745239
Train batch 297: Loss --- 0.3089085817337036
Train batch 298: Loss --- 0.2541426420211792
Train batch 299: Loss --- 0.35059481859207153
Train batch 301: Loss --- 0.43245220184326174
Train batch 302: Loss --- 0.3540617823600769
Train batch 303: Loss --- 0.564706027507782
Train batch 304: Loss --- 0.5301718711853027
Train batch 305: Loss --- 0.3067416846752167
Train batch 306: Loss --- 0.6138824224472046
Train batch 307: Loss --- 0.23947377502918243
Train batch 308: Loss --- 0.3585056662559509
Train batch 310: Loss --- 0.23041833937168124
Train batch 311: Loss --- 0.47317856550216675
Train batch 312: Loss --- 0.28964096307754517
Train batch 313: Loss --- 0.4581838846206665
Train batch 314: Loss --- 0.24433834850788116
Train batch 315: Loss --- 0.3356539309024811
Train batch 316: Loss --- 0.23283107578754425
Train batch 319: Loss --- 0.31280690431594854
Train batch 320: Loss --- 0.298821359872818
Train batch 321: Loss --- 0.33233320713043213
Train batch 322: Loss --- 0.3030077815055847
Train batch 319: Loss --- 0.31280690431594854
Traceback (most recent call last):
  File "tools/train.py", line 34, in <module>
    train_model(epochs, criterion, optimizer)
  File "tools/train.py", line 28, in train_model
    torch.save(model.state_dict(), "outputs")
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/serialization.py", line 628, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/serialization.py", line 502, in _open_zipfile_writer
    return container(name_or_buffer)
  File "/home/muneeb/Desktop/zuha/.env/lib/python3.8/site-packages/torch/serialization.py", line 473, in __init__
    super().__init__(torch._C.PyTorchFileWriter(self.name))
RuntimeError: File outputs cannot be opened.
Train batch 319: Loss --- 0.31280690431594854